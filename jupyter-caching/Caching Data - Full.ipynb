{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Caching Data\n",
    "\n",
    "Spark offers the possibility to cache data, which means that it tries to keep (intermediate) results either in memory or on disk. This can be very helpful in iterative algorithms or interactive analysis, where you want to prevent that the same processing steps are performed over and over again.\n",
    "\n",
    "### Approach to Caching\n",
    "Instead of performing timings of individual executions, we use the `explain()` method again to see how output changes with cached intermediate results.\n",
    "\n",
    "### Weather Example\n",
    "We will again use the weather example to understand how caching works."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create or Reuse Spark Session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.10/site-packages/pyspark/bin/load-spark-env.sh: line 68: ps: command not found\n",
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n",
      "23/11/25 17:25:44 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n",
      "23/11/25 17:25:45 WARN Utils: Service 'SparkUI' could not bind on port 4040. Attempting port 4041.\n",
      "23/11/25 17:25:45 WARN Utils: Service 'SparkUI' could not bind on port 4041. Attempting port 4042.\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "\n",
       "            <div>\n",
       "                <p><b>SparkSession - in-memory</b></p>\n",
       "                \n",
       "        <div>\n",
       "            <p><b>SparkContext</b></p>\n",
       "\n",
       "            <p><a href=\"http://fe49fe119e4f:4042\">Spark UI</a></p>\n",
       "\n",
       "            <dl>\n",
       "              <dt>Version</dt>\n",
       "                <dd><code>v3.4.0</code></dd>\n",
       "              <dt>Master</dt>\n",
       "                <dd><code>local[*]</code></dd>\n",
       "              <dt>AppName</dt>\n",
       "                <dd><code>pyspark-shell</code></dd>\n",
       "            </dl>\n",
       "        </div>\n",
       "        \n",
       "            </div>\n",
       "        "
      ],
      "text/plain": [
       "<pyspark.sql.session.SparkSession at 0x7f0808396fb0>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql import SparkSession\n",
    "import pyspark.sql.functions as f\n",
    "\n",
    "if not 'spark' in locals():\n",
    "    spark = SparkSession.builder \\\n",
    "        .master(\"local[*]\") \\\n",
    "        .config(\"spark.driver.memory\",\"24G\") \\\n",
    "        .getOrCreate()\n",
    "\n",
    "spark"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)\n",
    "spark.conf.set(\"spark.sql.autoBroadcastJoinThreshold\", -1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "\n",
    "First we load the weather data, which consists of the measurement data and some station metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "storageLocation = \"s3://dimajix-training/data/weather\"\n",
    "# storageLocation = \"/dimajix/data/weather-noaa-sample\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Measurements\n",
    "\n",
    "Measurements are stored in multiple directories (one per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "raw_weather = spark.read.text(storageLocation + \"/2003\").withColumn(\"year\", f.lit(2003))    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Measurements\n",
    "\n",
    "Measurements were stored in a proprietary text based format, with some values at fixed positions. We need to extract these values with a simple `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>usaf</th>\n",
       "      <th>wban</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_type</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_direction_qual</th>\n",
       "      <th>wind_observation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_speed_qual</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_temperature_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0000</td>\n",
       "      <td>SY-MT</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0017</td>\n",
       "      <td>FM-16</td>\n",
       "      <td>020</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0053</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0100</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0153</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0200</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0253</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0300</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0353</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>020</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0400</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    usaf   wban      date  time report_type wind_direction   \n",
       "0  2003  703160  25624  20030101  0000       SY-MT            010  \\\n",
       "1  2003  703160  25624  20030101  0017       FM-16            020   \n",
       "2  2003  703160  25624  20030101  0053       FM-15            010   \n",
       "3  2003  703160  25624  20030101  0100       NSRDB            999   \n",
       "4  2003  703160  25624  20030101  0153       FM-15            010   \n",
       "5  2003  703160  25624  20030101  0200       NSRDB            999   \n",
       "6  2003  703160  25624  20030101  0253       FM-15            010   \n",
       "7  2003  703160  25624  20030101  0300       NSRDB            999   \n",
       "8  2003  703160  25624  20030101  0353       FM-15            020   \n",
       "9  2003  703160  25624  20030101  0400       NSRDB            999   \n",
       "\n",
       "  wind_direction_qual wind_observation  wind_speed wind_speed_qual   \n",
       "0                   5                N         5.2               5  \\\n",
       "1                   1                N         4.6               1   \n",
       "2                   5                N         5.2               5   \n",
       "3                   9                9       999.9               9   \n",
       "4                   5                N         6.2               5   \n",
       "5                   9                9       999.9               9   \n",
       "6                   5                N         7.2               5   \n",
       "7                   9                9       999.9               9   \n",
       "8                   5                N         6.2               5   \n",
       "9                   9                9       999.9               9   \n",
       "\n",
       "   air_temperature air_temperature_qual  \n",
       "0             -0.6                    5  \n",
       "1             -2.0                    1  \n",
       "2             -2.8                    5  \n",
       "3            999.9                    9  \n",
       "4             -2.2                    5  \n",
       "5            999.9                    9  \n",
       "6             -3.3                    5  \n",
       "7            999.9                    9  \n",
       "8             -1.1                    5  \n",
       "9            999.9                    9  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = raw_weather.select(\n",
    "    f.col(\"year\"),\n",
    "    f.substring(f.col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    f.substring(f.col(\"value\"),11,5).alias(\"wban\"),\n",
    "    f.substring(f.col(\"value\"),16,8).alias(\"date\"),\n",
    "    f.substring(f.col(\"value\"),24,4).alias(\"time\"),\n",
    "    f.substring(f.col(\"value\"),42,5).alias(\"report_type\"),\n",
    "    f.substring(f.col(\"value\"),61,3).alias(\"wind_direction\"),\n",
    "    f.substring(f.col(\"value\"),64,1).alias(\"wind_direction_qual\"),\n",
    "    f.substring(f.col(\"value\"),65,1).alias(\"wind_observation\"),\n",
    "    (f.substring(f.col(\"value\"),66,4).cast(\"float\") / f.lit(10.0)).alias(\"wind_speed\"),\n",
    "    f.substring(f.col(\"value\"),70,1).alias(\"wind_speed_qual\"),\n",
    "    (f.substring(f.col(\"value\"),88,5).cast(\"float\") / f.lit(10.0)).alias(\"air_temperature\"),\n",
    "    f.substring(f.col(\"value\"),93,1).alias(\"air_temperature_qual\")\n",
    ")\n",
    "    \n",
    "weather.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Station Metadata\n",
    "\n",
    "We also need to load the weather station meta data containing information about the geo location, country etc of individual weather stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007018</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7018</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7018.0</td>\n",
       "      <td>20110309</td>\n",
       "      <td>20130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007026</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7026</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7026.0</td>\n",
       "      <td>20120713</td>\n",
       "      <td>20170822</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007070</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7070</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7070.0</td>\n",
       "      <td>20140923</td>\n",
       "      <td>20150926</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>008260</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD8270</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+0000.0</td>\n",
       "      <td>20050101</td>\n",
       "      <td>20100920</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>008268</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD8278</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+32.950</td>\n",
       "      <td>+065.567</td>\n",
       "      <td>+1156.7</td>\n",
       "      <td>20100519</td>\n",
       "      <td>20120323</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>008307</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 8318</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+8318.0</td>\n",
       "      <td>20100421</td>\n",
       "      <td>20100421</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>008411</td>\n",
       "      <td>99999</td>\n",
       "      <td>XM20</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20160217</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>008414</td>\n",
       "      <td>99999</td>\n",
       "      <td>XM18</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20160216</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>008415</td>\n",
       "      <td>99999</td>\n",
       "      <td>XM21</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20160217</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>008418</td>\n",
       "      <td>99999</td>\n",
       "      <td>XM24</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20160217</td>\n",
       "      <td>20160217</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USAF   WBAN STATION NAME  CTRY STATE  ICAO      LAT       LON  ELEV(M)   \n",
       "0  007018  99999   WXPOD 7018  None  None  None  +00.000  +000.000  +7018.0  \\\n",
       "1  007026  99999   WXPOD 7026    AF  None  None  +00.000  +000.000  +7026.0   \n",
       "2  007070  99999   WXPOD 7070    AF  None  None  +00.000  +000.000  +7070.0   \n",
       "3  008260  99999    WXPOD8270  None  None  None  +00.000  +000.000  +0000.0   \n",
       "4  008268  99999    WXPOD8278    AF  None  None  +32.950  +065.567  +1156.7   \n",
       "5  008307  99999   WXPOD 8318    AF  None  None  +00.000  +000.000  +8318.0   \n",
       "6  008411  99999         XM20  None  None  None     None      None     None   \n",
       "7  008414  99999         XM18  None  None  None     None      None     None   \n",
       "8  008415  99999         XM21  None  None  None     None      None     None   \n",
       "9  008418  99999         XM24  None  None  None     None      None     None   \n",
       "\n",
       "      BEGIN       END  \n",
       "0  20110309  20130730  \n",
       "1  20120713  20170822  \n",
       "2  20140923  20150926  \n",
       "3  20050101  20100920  \n",
       "4  20100519  20120323  \n",
       "5  20100421  20100421  \n",
       "6  20160217  20160217  \n",
       "7  20160216  20160217  \n",
       "8  20160217  20160217  \n",
       "9  20160217  20160217  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(storageLocation + \"/isd-history\")\n",
    "\n",
    "# Display first 10 records    \n",
    "stations.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Caching Data\n",
    "\n",
    "For analysing the impact of cachign data, we will use a slightly simplified variant of the weather analysis (only temperature will be aggregated). We will change the execution by caching intermediate results and watch how execution plans change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Original Execution Plan\n",
    "\n",
    "First let's have the execution plans of the original query as our reference."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "joined_weather = weather.join(stations, [\"usaf\", \"wban\"])\n",
    "aggregates = joined_weather.groupBy(joined_weather.CTRY, joined_weather.year).agg(\n",
    "        f.min(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('min_temp'),\n",
    "        f.max(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('max_temp')\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(14) Project [CTRY#52, 2003 AS year#2, usaf#6, wban#7, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59, min_temp#128, max_temp#130]\n",
      "+- *(14) SortMergeJoin [CTRY#52], [CTRY#139], Inner\n",
      "   :- *(6) Sort [CTRY#52 ASC NULLS FIRST], false, 0\n",
      "   :  +- Exchange hashpartitioning(CTRY#52, 200), ENSURE_REQUIREMENTS, [plan_id=153]\n",
      "   :     +- *(5) Project [usaf#6, wban#7, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, CTRY#52, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59]\n",
      "   :        +- *(5) SortMergeJoin [usaf#6, wban#7], [USAF#49, WBAN#50], Inner\n",
      "   :           :- *(2) Sort [usaf#6 ASC NULLS FIRST, wban#7 ASC NULLS FIRST], false, 0\n",
      "   :           :  +- Exchange hashpartitioning(usaf#6, wban#7, 200), ENSURE_REQUIREMENTS, [plan_id=137]\n",
      "   :           :     +- *(1) Project [substring(value#0, 5, 6) AS usaf#6, substring(value#0, 11, 5) AS wban#7, substring(value#0, 16, 8) AS date#8, substring(value#0, 24, 4) AS time#9, substring(value#0, 42, 5) AS report_type#10, substring(value#0, 61, 3) AS wind_direction#11, substring(value#0, 64, 1) AS wind_direction_qual#12, substring(value#0, 65, 1) AS wind_observation#13, (cast(cast(substring(value#0, 66, 4) as float) as double) / 10.0) AS wind_speed#14, substring(value#0, 70, 1) AS wind_speed_qual#15, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#16, substring(value#0, 93, 1) AS air_temperature_qual#17]\n",
      "   :           :        +- *(1) Filter (isnotnull(substring(value#0, 5, 6)) AND isnotnull(substring(value#0, 11, 5)))\n",
      "   :           :           +- FileScan text [value#0] Batched: false, DataFilters: [isnotnull(substring(value#0, 5, 6)), isnotnull(substring(value#0, 11, 5))], Format: Text, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "   :           +- *(4) Sort [USAF#49 ASC NULLS FIRST, WBAN#50 ASC NULLS FIRST], false, 0\n",
      "   :              +- Exchange hashpartitioning(USAF#49, WBAN#50, 200), ENSURE_REQUIREMENTS, [plan_id=145]\n",
      "   :                 +- *(3) Filter ((isnotnull(USAF#49) AND isnotnull(WBAN#50)) AND isnotnull(CTRY#52))\n",
      "   :                    +- FileScan csv [USAF#49,WBAN#50,STATION NAME#51,CTRY#52,STATE#53,ICAO#54,LAT#55,LON#56,ELEV(M)#57,BEGIN#58,END#59] Batched: false, DataFilters: [isnotnull(USAF#49), isnotnull(WBAN#50), isnotnull(CTRY#52)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN), IsNotNull(CTRY)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n",
      "   +- *(13) Sort [CTRY#139 ASC NULLS FIRST], false, 0\n",
      "      +- Exchange hashpartitioning(CTRY#139, 200), ENSURE_REQUIREMENTS, [plan_id=183]\n",
      "         +- *(12) HashAggregate(keys=[CTRY#139, 2003#174], functions=[min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "            +- Exchange hashpartitioning(CTRY#139, 2003#174, 200), ENSURE_REQUIREMENTS, [plan_id=179]\n",
      "               +- *(11) HashAggregate(keys=[CTRY#139, 2003 AS 2003#174], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), partial_max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "                  +- *(11) Project [air_temperature#16, air_temperature_qual#17, CTRY#139]\n",
      "                     +- *(11) SortMergeJoin [usaf#6, wban#7], [USAF#136, WBAN#137], Inner\n",
      "                        :- *(8) Sort [usaf#6 ASC NULLS FIRST, wban#7 ASC NULLS FIRST], false, 0\n",
      "                        :  +- Exchange hashpartitioning(usaf#6, wban#7, 200), ENSURE_REQUIREMENTS, [plan_id=162]\n",
      "                        :     +- *(7) Project [substring(value#135, 5, 6) AS usaf#6, substring(value#135, 11, 5) AS wban#7, (cast(cast(substring(value#135, 88, 5) as float) as double) / 10.0) AS air_temperature#16, substring(value#135, 93, 1) AS air_temperature_qual#17]\n",
      "                        :        +- *(7) Filter (isnotnull(substring(value#135, 5, 6)) AND isnotnull(substring(value#135, 11, 5)))\n",
      "                        :           +- FileScan text [value#135] Batched: false, DataFilters: [isnotnull(substring(value#135, 5, 6)), isnotnull(substring(value#135, 11, 5))], Format: Text, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "                        +- *(10) Sort [USAF#136 ASC NULLS FIRST, WBAN#137 ASC NULLS FIRST], false, 0\n",
      "                           +- Exchange hashpartitioning(USAF#136, WBAN#137, 200), ENSURE_REQUIREMENTS, [plan_id=170]\n",
      "                              +- *(9) Filter ((isnotnull(USAF#136) AND isnotnull(WBAN#137)) AND isnotnull(CTRY#139))\n",
      "                                 +- FileScan csv [USAF#136,WBAN#137,CTRY#139] Batched: false, DataFilters: [isnotnull(USAF#136), isnotnull(WBAN#137), isnotnull(CTRY#139)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN), IsNotNull(CTRY)], ReadSchema: struct<USAF:string,WBAN:string,CTRY:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = joined_weather.join(f.broadcast(aggregates), [\"ctry\", \"year\"])\n",
    "\n",
    "result.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Caching Weather\n",
    "\n",
    "First let us simply cache the joined input DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[usaf: string, wban: string, year: int, date: string, time: string, report_type: string, wind_direction: string, wind_direction_qual: string, wind_observation: string, wind_speed: double, wind_speed_qual: string, air_temperature: double, air_temperature_qual: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_weather.cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Forcing physical caching\n",
    "\n",
    "The `cache()` method again works lazily and only marks the DataFrame to be cached. The physical cache itself will only take place once the elements are evaluated. A common and easy way to enforce this is to call a `count()` on the to-be cached DataFrame."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 5:==================================================>   (187 + 13) / 200]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 25.9 ms, sys: 13.5 ms, total: 39.4 ms\n",
      "Wall time: 9.12 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1807253"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "joined_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When you now perform `count` a second time, it should be much faster"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 0 ns, sys: 2.25 ms, total: 2.25 ms\n",
      "Wall time: 356 ms\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "1807253"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "joined_weather.count()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execution Plan with Cache\n",
    "\n",
    "Now let us have a look at the execution plan with the cache for the `weather` DataFrame enabled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(3) Project [CTRY#52, year#2, usaf#6, wban#7, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59, min_temp#1484, max_temp#1486]\n",
      "+- *(3) BroadcastHashJoin [CTRY#52, year#2], [CTRY#1495, year#1503], Inner, BuildRight, false\n",
      "   :- *(3) Filter isnotnull(CTRY#52)\n",
      "   :  +- InMemoryTableScan [usaf#6, wban#7, year#2, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, CTRY#52, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59], [isnotnull(CTRY#52)]\n",
      "   :        +- InMemoryRelation [usaf#6, wban#7, year#2, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, CTRY#52, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "   :              +- *(5) Project [usaf#6, wban#7, 2003 AS year#2, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, CTRY#52, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59]\n",
      "   :                 +- *(5) SortMergeJoin [usaf#6, wban#7], [USAF#49, WBAN#50], Inner\n",
      "   :                    :- *(2) Sort [usaf#6 ASC NULLS FIRST, wban#7 ASC NULLS FIRST], false, 0\n",
      "   :                    :  +- Exchange hashpartitioning(usaf#6, wban#7, 200), ENSURE_REQUIREMENTS, [plan_id=301]\n",
      "   :                    :     +- *(1) Project [substring(value#0, 5, 6) AS usaf#6, substring(value#0, 11, 5) AS wban#7, substring(value#0, 16, 8) AS date#8, substring(value#0, 24, 4) AS time#9, substring(value#0, 42, 5) AS report_type#10, substring(value#0, 61, 3) AS wind_direction#11, substring(value#0, 64, 1) AS wind_direction_qual#12, substring(value#0, 65, 1) AS wind_observation#13, (cast(cast(substring(value#0, 66, 4) as float) as double) / 10.0) AS wind_speed#14, substring(value#0, 70, 1) AS wind_speed_qual#15, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#16, substring(value#0, 93, 1) AS air_temperature_qual#17]\n",
      "   :                    :        +- *(1) Filter (isnotnull(substring(value#0, 5, 6)) AND isnotnull(substring(value#0, 11, 5)))\n",
      "   :                    :           +- FileScan text [value#0] Batched: false, DataFilters: [isnotnull(substring(value#0, 5, 6)), isnotnull(substring(value#0, 11, 5))], Format: Text, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "   :                    +- *(4) Sort [USAF#49 ASC NULLS FIRST, WBAN#50 ASC NULLS FIRST], false, 0\n",
      "   :                       +- Exchange hashpartitioning(USAF#49, WBAN#50, 200), ENSURE_REQUIREMENTS, [plan_id=309]\n",
      "   :                          +- *(3) Filter (isnotnull(USAF#49) AND isnotnull(WBAN#50))\n",
      "   :                             +- FileScan csv [USAF#49,WBAN#50,STATION NAME#51,CTRY#52,STATE#53,ICAO#54,LAT#55,LON#56,ELEV(M)#57,BEGIN#58,END#59] Batched: false, DataFilters: [isnotnull(USAF#49), isnotnull(WBAN#50)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n",
      "   +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, int, false]),false), [plan_id=425]\n",
      "      +- *(2) HashAggregate(keys=[CTRY#1495, year#1503], functions=[min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "         +- Exchange hashpartitioning(CTRY#1495, year#1503, 200), ENSURE_REQUIREMENTS, [plan_id=421]\n",
      "            +- *(1) HashAggregate(keys=[CTRY#1495, year#1503], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), partial_max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "               +- *(1) Filter isnotnull(CTRY#1495)\n",
      "                  +- InMemoryTableScan [year#1503, air_temperature#16, air_temperature_qual#17, CTRY#1495], [isnotnull(CTRY#1495)]\n",
      "                        +- InMemoryRelation [usaf#6, wban#7, year#1503, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#1494, CTRY#1495, STATE#1496, ICAO#1497, LAT#1498, LON#1499, ELEV(M)#1500, BEGIN#1501, END#1502], StorageLevel(disk, memory, deserialized, 1 replicas)\n",
      "                              +- *(5) Project [usaf#6, wban#7, 2003 AS year#2, date#8, time#9, report_type#10, wind_direction#11, wind_direction_qual#12, wind_observation#13, wind_speed#14, wind_speed_qual#15, air_temperature#16, air_temperature_qual#17, STATION NAME#51, CTRY#52, STATE#53, ICAO#54, LAT#55, LON#56, ELEV(M)#57, BEGIN#58, END#59]\n",
      "                                 +- *(5) SortMergeJoin [usaf#6, wban#7], [USAF#49, WBAN#50], Inner\n",
      "                                    :- *(2) Sort [usaf#6 ASC NULLS FIRST, wban#7 ASC NULLS FIRST], false, 0\n",
      "                                    :  +- Exchange hashpartitioning(usaf#6, wban#7, 200), ENSURE_REQUIREMENTS, [plan_id=301]\n",
      "                                    :     +- *(1) Project [substring(value#0, 5, 6) AS usaf#6, substring(value#0, 11, 5) AS wban#7, substring(value#0, 16, 8) AS date#8, substring(value#0, 24, 4) AS time#9, substring(value#0, 42, 5) AS report_type#10, substring(value#0, 61, 3) AS wind_direction#11, substring(value#0, 64, 1) AS wind_direction_qual#12, substring(value#0, 65, 1) AS wind_observation#13, (cast(cast(substring(value#0, 66, 4) as float) as double) / 10.0) AS wind_speed#14, substring(value#0, 70, 1) AS wind_speed_qual#15, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#16, substring(value#0, 93, 1) AS air_temperature_qual#17]\n",
      "                                    :        +- *(1) Filter (isnotnull(substring(value#0, 5, 6)) AND isnotnull(substring(value#0, 11, 5)))\n",
      "                                    :           +- FileScan text [value#0] Batched: false, DataFilters: [isnotnull(substring(value#0, 5, 6)), isnotnull(substring(value#0, 11, 5))], Format: Text, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "                                    +- *(4) Sort [USAF#49 ASC NULLS FIRST, WBAN#50 ASC NULLS FIRST], false, 0\n",
      "                                       +- Exchange hashpartitioning(USAF#49, WBAN#50, 200), ENSURE_REQUIREMENTS, [plan_id=309]\n",
      "                                          +- *(3) Filter (isnotnull(USAF#49) AND isnotnull(WBAN#50))\n",
      "                                             +- FileScan csv [USAF#49,WBAN#50,STATION NAME#51,CTRY#52,STATE#53,ICAO#54,LAT#55,LON#56,ELEV(M)#57,BEGIN#58,END#59] Batched: false, DataFilters: [isnotnull(USAF#49), isnotnull(WBAN#50)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "aggregates = joined_weather.groupBy(joined_weather.CTRY, joined_weather.year).agg(\n",
    "        f.min(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('min_temp'),\n",
    "        f.max(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('max_temp')\n",
    "    )\n",
    "\n",
    "result = joined_weather.join(f.broadcast(aggregates), [\"ctry\", \"year\"])\n",
    "\n",
    "result.explain()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTRY</th>\n",
       "      <th>year</th>\n",
       "      <th>usaf</th>\n",
       "      <th>wban</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_type</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_direction_qual</th>\n",
       "      <th>wind_observation</th>\n",
       "      <th>...</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0000</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0200</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0300</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0500</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>230</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0600</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>240</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0800</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0900</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>1100</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>210</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>1200</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>200</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>AS</td>\n",
       "      <td>2003</td>\n",
       "      <td>954920</td>\n",
       "      <td>99999</td>\n",
       "      <td>20030101</td>\n",
       "      <td>1400</td>\n",
       "      <td>FM-12</td>\n",
       "      <td>190</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>...</td>\n",
       "      <td>THARGOMINDAH</td>\n",
       "      <td>None</td>\n",
       "      <td>YTGM</td>\n",
       "      <td>-27.986</td>\n",
       "      <td>+143.811</td>\n",
       "      <td>+0132.0</td>\n",
       "      <td>20010705</td>\n",
       "      <td>20200205</td>\n",
       "      <td>0.3</td>\n",
       "      <td>45.8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 24 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "  CTRY  year    usaf   wban      date  time report_type wind_direction   \n",
       "0   AS  2003  954920  99999  20030101  0000       FM-12            200  \\\n",
       "1   AS  2003  954920  99999  20030101  0200       FM-12            230   \n",
       "2   AS  2003  954920  99999  20030101  0300       FM-12            220   \n",
       "3   AS  2003  954920  99999  20030101  0500       FM-12            230   \n",
       "4   AS  2003  954920  99999  20030101  0600       FM-12            240   \n",
       "5   AS  2003  954920  99999  20030101  0800       FM-12            210   \n",
       "6   AS  2003  954920  99999  20030101  0900       FM-12            220   \n",
       "7   AS  2003  954920  99999  20030101  1100       FM-12            210   \n",
       "8   AS  2003  954920  99999  20030101  1200       FM-12            200   \n",
       "9   AS  2003  954920  99999  20030101  1400       FM-12            190   \n",
       "\n",
       "  wind_direction_qual wind_observation  ...  STATION NAME STATE  ICAO   \n",
       "0                   1                N  ...  THARGOMINDAH  None  YTGM  \\\n",
       "1                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "2                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "3                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "4                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "5                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "6                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "7                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "8                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "9                   1                N  ...  THARGOMINDAH  None  YTGM   \n",
       "\n",
       "       LAT       LON  ELEV(M)     BEGIN       END min_temp max_temp  \n",
       "0  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "1  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "2  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "3  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "4  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "5  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "6  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "7  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "8  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "9  -27.986  +143.811  +0132.0  20010705  20200205      0.3     45.8  \n",
       "\n",
       "[10 rows x 24 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "Although the data is already cached, the execution plan still contains all steps. But the caching step won't be executed any more (since data is already cached), it is only mentioned here for completenss of the plan. We will see in the web interface.\n",
    "\n",
    "The cache itself is presented as two steps in the execution plan:\n",
    "* Creating the cache (InMemoryRelation)\n",
    "* Using the cache (InMemoryTableScan)\n",
    "\n",
    "If you look closely at the execution plans and compare these to the original uncached plan, you will notice that certain optimizations are not performed any more:\n",
    "* Cache contains ALL columns of the weather DataFrame, although only a subset is required.\n",
    "* Filter operation of JOIN is performed part of caching.\n",
    "\n",
    "Caching is an optimization barrier. This means that Spark can only optimize plans before building the cache and plans after using the cache. No optimization is possible that spans building and using the cache. The idea simply is that the DataFrame should be cached exactly how it was specified without any column truncating or record filtering in place which appears after the cache."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Uncaching Data\n",
    "\n",
    "Caches occupy resources (memory and/or disk). Once you do not need the cache any more, you'd probably like to free up the resources again. This is easily possible with the `unpersist()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[usaf: string, wban: string, year: int, date: string, time: string, report_type: string, wind_direction: string, wind_direction_qual: string, wind_observation: string, wind_speed: double, wind_speed_qual: string, air_temperature: double, air_temperature_qual: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "joined_weather.unpersist()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Exeuction plan after unpersist\n",
    "\n",
    "Now we'd expect to have the original execution plan again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(6) HashAggregate(keys=[CTRY#52, 2003#3336], functions=[min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "+- Exchange hashpartitioning(CTRY#52, 2003#3336, 200), ENSURE_REQUIREMENTS, [plan_id=576]\n",
      "   +- *(5) HashAggregate(keys=[CTRY#52, 2003 AS 2003#3336], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END), partial_max(CASE WHEN (cast(air_temperature_qual#17 as int) = 1) THEN air_temperature#16 END)])\n",
      "      +- *(5) Project [air_temperature#16, air_temperature_qual#17, CTRY#52]\n",
      "         +- *(5) SortMergeJoin [usaf#6, wban#7], [USAF#49, WBAN#50], Inner\n",
      "            :- *(2) Sort [usaf#6 ASC NULLS FIRST, wban#7 ASC NULLS FIRST], false, 0\n",
      "            :  +- Exchange hashpartitioning(usaf#6, wban#7, 200), ENSURE_REQUIREMENTS, [plan_id=559]\n",
      "            :     +- *(1) Project [substring(value#0, 5, 6) AS usaf#6, substring(value#0, 11, 5) AS wban#7, (cast(cast(substring(value#0, 88, 5) as float) as double) / 10.0) AS air_temperature#16, substring(value#0, 93, 1) AS air_temperature_qual#17]\n",
      "            :        +- *(1) Filter (isnotnull(substring(value#0, 5, 6)) AND isnotnull(substring(value#0, 11, 5)))\n",
      "            :           +- FileScan text [value#0] Batched: false, DataFilters: [isnotnull(substring(value#0, 5, 6)), isnotnull(substring(value#0, 11, 5))], Format: Text, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "            +- *(4) Sort [USAF#49 ASC NULLS FIRST, WBAN#50 ASC NULLS FIRST], false, 0\n",
      "               +- Exchange hashpartitioning(USAF#49, WBAN#50, 200), ENSURE_REQUIREMENTS, [plan_id=567]\n",
      "                  +- *(3) Filter (isnotnull(USAF#49) AND isnotnull(WBAN#50))\n",
      "                     +- FileScan csv [USAF#49,WBAN#50,CTRY#52] Batched: false, DataFilters: [isnotnull(USAF#49), isnotnull(WBAN#50)], Format: CSV, Location: InMemoryFileIndex(1 paths)[file:/dimajix/data/weather-noaa-sample/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,CTRY:string>\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "result = joined_weather.groupBy(joined_weather.CTRY, joined_weather.year).agg(\n",
    "        f.min(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('min_temp'),\n",
    "        f.max(f.when(joined_weather.air_temperature_qual == f.lit(1), joined_weather.air_temperature)).alias('max_temp')\n",
    "    )\n",
    "\n",
    "result.explain(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "As you see in the execution plan, the cache has been removed now and the plan equals to the original one before we started caching data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3 Cache Levels\n",
    "\n",
    "Spark supports different levels of cache (memory, disk and a combination). These can be specified explicitly if you use `persist()` instead of `cache()`. Cache actually is a shortcut for `persist(MEMORY_AND_DISK)`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "23/11/25 17:26:55 WARN CacheManager: Asked to cache already cached data.\n",
      "23/11/25 17:26:55 WARN CacheManager: Asked to cache already cached data.\n",
      "23/11/25 17:26:55 WARN CacheManager: Asked to cache already cached data.\n",
      "23/11/25 17:26:55 WARN CacheManager: Asked to cache already cached data.\n",
      "23/11/25 17:26:55 WARN CacheManager: Asked to cache already cached data.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "DataFrame[usaf: string, wban: string, year: int, date: string, time: string, report_type: string, wind_direction: string, wind_direction_qual: string, wind_observation: string, wind_speed: double, wind_speed_qual: string, air_temperature: double, air_temperature_qual: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.storagelevel import StorageLevel\n",
    "\n",
    "joined_weather.persist(StorageLevel.MEMORY_ONLY)\n",
    "joined_weather.persist(StorageLevel.DISK_ONLY)\n",
    "joined_weather.persist(StorageLevel.MEMORY_AND_DISK)\n",
    "\n",
    "joined_weather.persist(StorageLevel.MEMORY_ONLY_2)\n",
    "joined_weather.persist(StorageLevel.DISK_ONLY_2)\n",
    "joined_weather.persist(StorageLevel.MEMORY_AND_DISK_2)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Cache level explanation\n",
    "\n",
    "* `MEMORY_ONLY` - stores all records directly in memory\n",
    "* `DISK_ONLY` - stores all records serialized on disk\n",
    "* `MEMORY_AND_DISK` - stores all records first in memory and spills onto disk when no space is left in memory\n",
    "* `..._2` - stores caches on two nodes instead of one for additional redundancy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4 Don'ts\n",
    "\n",
    "Although reading from a cache can be faster than reprocessing data from scratch, especially if that involves reading original data from slow IO devices (S3) or complex operations (joins), some caution should be taken. Caching is not free, not only is it a optimization barrier, it also occupies resources (memory and disk) and definately slows down the first query that has to build the cache.\n",
    "\n",
    "In order to limit the physical resources (RAM and disk), you should reduce the amount to cache to the bare minimum and even exclude simple calculations from the cache. For example if we included conversions to mph and °F in our weather data as precalculated measurements, it would be a wise idea to exclude these simple calculations from the cache, since they would only blow up the overall volume while these conversions are simple and cheap to calculate even after reading from the cache (plus they can be removed by the optimizer when they are not needed in a specific query)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[year: int, usaf: string, wban: string, date: string, time: string, report_type: string, wind_direction: string, wind_direction_qual: string, wind_observation: string, wind_speed: double, wind_speed_qual: string, air_temperature: double, air_temperature_qual: string, air_temperature_fahrenheit: double, wind_speed_mph: double]"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Remove any previous caches\n",
    "weather.unpersist()\n",
    "\n",
    "weather_intl = weather.withColumn(\"air_temperature_fahrenheit\", weather[\"air_temperature\"]*9.0/5.0+32) \\\n",
    "        .withColumn(\"wind_speed_mph\", weather[\"wind_speed\"]*2.236936)\n",
    "\n",
    "# DON'T !\n",
    "weather_intl.cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove any previous caches\n",
    "weather_intl.unpersist()\n",
    "\n",
    "# Prefer caching the smaller input data set and perform trivial calculations after caching\n",
    "weather.cache()\n",
    "weather_intl = weather.withColumn(\"air_temperature_fahrenheit\", weather[\"air_temperature\"]*9.0/5.0+32) \\\n",
    "        .withColumn(\"wind_speed_mph\", weather[\"wind_speed\"]*2.236936)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
