{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Execution Plan\n",
    "\n",
    "In this notebook we try to understand Spark execution plans. We will use the weather example and analyse all the steps in order to get a better understanding.\n",
    "\n",
    "## Exeuction Model of Spark\n",
    "\n",
    "In contrast to many other (mainly non-distributed) frameworks, Spark does not execute any transformation immediately, but only records the step and builds a so called execution plan. This plan is the basis for Sparks resilience against failure of individual nodes (since the result can be reconstructed from the execution plan), but also allows Spark to perform optimizations which span all transformation steps.\n",
    "\n",
    "Specifically with Spark DataFrames (as opposed to the more low level RDD interface), Spark uses an advanced optimizer. The general steps of query processing in response to an action (like a \"show\" or \"save\" action)\" are always as follows:\n",
    "1. Parse logical execution plan\n",
    "2. Analyze logical execution plan and resolve all symbols (tables, columns, functions)\n",
    "3. Optimize logical execution plan\n",
    "4. Create physical execution plan by mapping all steps to RDD operations\n",
    "\n",
    "## Relation to RDDs\n",
    "Note that RDDs are only used in the very last step, although the general conception is that DataFrames sit on top of RDDs. But the point is, that a DataFrame first collects all transformations on a higher level of abstraction and RDDs only come into play in this very last step.\n",
    "\n",
    "Actually you can access an RDD of any DataFrame. BUT: This access will actually create the physical execution plan for this specific RDD. Before accessing this RDD it even didn't exist. This also means that using a DataFrames RDD actually is an optimization barrier.\n",
    "\n",
    "## Weather Example\n",
    "\n",
    "In the following steps, we will try to understand how Spark executes a simplified version of the weather analysis including aggregations and joins."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "spark.conf.set(\"spark.sql.adaptive.enabled\", False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Load Data\n",
    "\n",
    "First we load the weather data, which consists of the measurement data and some station metadata."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "storageLocation = \"s3://dimajix-training/data/weather\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.1 Load Measurements\n",
    "\n",
    "Measurements are stored in multiple directories (one per year)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>value</th>\n",
       "      <th>year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0494703160256242003010100003+55200-162717SY-MT...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0228703160256242003010100174+55200-162730FM-16...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>044070316025624200301010053C+55200-162717FM-15...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0071703160256242003010101009+55200-162717NSRDB...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>042770316025624200301010153C+55200-162717FM-15...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0071703160256242003010102009+55200-162717NSRDB...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>046870316025624200301010253C+55200-162717FM-15...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0071703160256242003010103009+55200-162717NSRDB...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>041570316025624200301010353C+55200-162717FM-15...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0054703160256242003010104009+55200-162717NSRDB...</td>\n",
       "      <td>2003</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               value  year\n",
       "0  0494703160256242003010100003+55200-162717SY-MT...  2003\n",
       "1  0228703160256242003010100174+55200-162730FM-16...  2003\n",
       "2  044070316025624200301010053C+55200-162717FM-15...  2003\n",
       "3  0071703160256242003010101009+55200-162717NSRDB...  2003\n",
       "4  042770316025624200301010153C+55200-162717FM-15...  2003\n",
       "5  0071703160256242003010102009+55200-162717NSRDB...  2003\n",
       "6  046870316025624200301010253C+55200-162717FM-15...  2003\n",
       "7  0071703160256242003010103009+55200-162717NSRDB...  2003\n",
       "8  041570316025624200301010353C+55200-162717FM-15...  2003\n",
       "9  0054703160256242003010104009+55200-162717NSRDB...  2003"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyspark.sql.functions import *\n",
    "from functools import reduce\n",
    "\n",
    "# Read in all years, store them in an Python array\n",
    "raw_weather_per_year = [spark.read.text(storageLocation + \"/\" + str(i)).withColumn(\"year\", lit(i)) for i in range(2003,2006)]\n",
    "\n",
    "# Union all years together\n",
    "raw_weather = reduce(lambda l,r: l.union(r), raw_weather_per_year)                        \n",
    "\n",
    "# Display first 10 records\n",
    "raw_weather.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Measurements\n",
    "\n",
    "Measurements were stored in a proprietary text based format, with some values at fixed positions. We need to extract these values with a simple `SELECT` statement."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>usaf</th>\n",
       "      <th>wban</th>\n",
       "      <th>date</th>\n",
       "      <th>time</th>\n",
       "      <th>report_type</th>\n",
       "      <th>wind_direction</th>\n",
       "      <th>wind_direction_qual</th>\n",
       "      <th>wind_observation</th>\n",
       "      <th>wind_speed</th>\n",
       "      <th>wind_speed_qual</th>\n",
       "      <th>air_temperature</th>\n",
       "      <th>air_temperature_qual</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0000</td>\n",
       "      <td>SY-MT</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-0.6</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0017</td>\n",
       "      <td>FM-16</td>\n",
       "      <td>020</td>\n",
       "      <td>1</td>\n",
       "      <td>N</td>\n",
       "      <td>4.6</td>\n",
       "      <td>1</td>\n",
       "      <td>-2.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0053</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>5.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0100</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0153</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-2.2</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0200</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0253</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>010</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>7.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-3.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0300</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0353</td>\n",
       "      <td>FM-15</td>\n",
       "      <td>020</td>\n",
       "      <td>5</td>\n",
       "      <td>N</td>\n",
       "      <td>6.2</td>\n",
       "      <td>5</td>\n",
       "      <td>-1.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>2003</td>\n",
       "      <td>703160</td>\n",
       "      <td>25624</td>\n",
       "      <td>20030101</td>\n",
       "      <td>0400</td>\n",
       "      <td>NSRDB</td>\n",
       "      <td>999</td>\n",
       "      <td>9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "      <td>999.9</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   year    usaf   wban      date  time report_type wind_direction  \\\n",
       "0  2003  703160  25624  20030101  0000       SY-MT            010   \n",
       "1  2003  703160  25624  20030101  0017       FM-16            020   \n",
       "2  2003  703160  25624  20030101  0053       FM-15            010   \n",
       "3  2003  703160  25624  20030101  0100       NSRDB            999   \n",
       "4  2003  703160  25624  20030101  0153       FM-15            010   \n",
       "5  2003  703160  25624  20030101  0200       NSRDB            999   \n",
       "6  2003  703160  25624  20030101  0253       FM-15            010   \n",
       "7  2003  703160  25624  20030101  0300       NSRDB            999   \n",
       "8  2003  703160  25624  20030101  0353       FM-15            020   \n",
       "9  2003  703160  25624  20030101  0400       NSRDB            999   \n",
       "\n",
       "  wind_direction_qual wind_observation  wind_speed wind_speed_qual  \\\n",
       "0                   5                N         5.2               5   \n",
       "1                   1                N         4.6               1   \n",
       "2                   5                N         5.2               5   \n",
       "3                   9                9       999.9               9   \n",
       "4                   5                N         6.2               5   \n",
       "5                   9                9       999.9               9   \n",
       "6                   5                N         7.2               5   \n",
       "7                   9                9       999.9               9   \n",
       "8                   5                N         6.2               5   \n",
       "9                   9                9       999.9               9   \n",
       "\n",
       "   air_temperature air_temperature_qual  \n",
       "0             -0.6                    5  \n",
       "1             -2.0                    1  \n",
       "2             -2.8                    5  \n",
       "3            999.9                    9  \n",
       "4             -2.2                    5  \n",
       "5            999.9                    9  \n",
       "6             -3.3                    5  \n",
       "7            999.9                    9  \n",
       "8             -1.1                    5  \n",
       "9            999.9                    9  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weather = raw_weather.select(\n",
    "    col(\"year\"),\n",
    "    substring(col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    substring(col(\"value\"),11,5).alias(\"wban\"),\n",
    "    substring(col(\"value\"),16,8).alias(\"date\"),\n",
    "    substring(col(\"value\"),24,4).alias(\"time\"),\n",
    "    substring(col(\"value\"),42,5).alias(\"report_type\"),\n",
    "    substring(col(\"value\"),61,3).alias(\"wind_direction\"),\n",
    "    substring(col(\"value\"),64,1).alias(\"wind_direction_qual\"),\n",
    "    substring(col(\"value\"),65,1).alias(\"wind_observation\"),\n",
    "    (substring(col(\"value\"),66,4).cast(\"float\") / lit(10.0)).alias(\"wind_speed\"),\n",
    "    substring(col(\"value\"),70,1).alias(\"wind_speed_qual\"),\n",
    "    (substring(col(\"value\"),88,5).cast(\"float\") / lit(10.0)).alias(\"air_temperature\"),\n",
    "    substring(col(\"value\"),93,1).alias(\"air_temperature_qual\")\n",
    ")\n",
    "    \n",
    "weather.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.2 Load Station Metadata\n",
    "\n",
    "We also need to load the weather station meta data containing information about the geo location, country etc of individual weather stations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>USAF</th>\n",
       "      <th>WBAN</th>\n",
       "      <th>STATION NAME</th>\n",
       "      <th>CTRY</th>\n",
       "      <th>STATE</th>\n",
       "      <th>ICAO</th>\n",
       "      <th>LAT</th>\n",
       "      <th>LON</th>\n",
       "      <th>ELEV(M)</th>\n",
       "      <th>BEGIN</th>\n",
       "      <th>END</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>007005</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07005</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>007011</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07011</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20111025</td>\n",
       "      <td>20121129</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>007018</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7018</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7018.0</td>\n",
       "      <td>20110309</td>\n",
       "      <td>20130730</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>007025</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07025</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>007026</td>\n",
       "      <td>99999</td>\n",
       "      <td>WXPOD 7026</td>\n",
       "      <td>AF</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>+00.000</td>\n",
       "      <td>+000.000</td>\n",
       "      <td>+7026.0</td>\n",
       "      <td>20120713</td>\n",
       "      <td>20141120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>007034</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07034</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20121024</td>\n",
       "      <td>20121106</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>007037</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07037</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20111202</td>\n",
       "      <td>20121125</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>007044</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07044</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120127</td>\n",
       "      <td>20120127</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>007047</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07047</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20120613</td>\n",
       "      <td>20120717</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>007052</td>\n",
       "      <td>99999</td>\n",
       "      <td>CWOS 07052</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>None</td>\n",
       "      <td>20121129</td>\n",
       "      <td>20121130</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     USAF   WBAN STATION NAME  CTRY STATE  ICAO      LAT       LON  ELEV(M)  \\\n",
       "0  007005  99999   CWOS 07005  None  None  None     None      None     None   \n",
       "1  007011  99999   CWOS 07011  None  None  None     None      None     None   \n",
       "2  007018  99999   WXPOD 7018  None  None  None  +00.000  +000.000  +7018.0   \n",
       "3  007025  99999   CWOS 07025  None  None  None     None      None     None   \n",
       "4  007026  99999   WXPOD 7026    AF  None  None  +00.000  +000.000  +7026.0   \n",
       "5  007034  99999   CWOS 07034  None  None  None     None      None     None   \n",
       "6  007037  99999   CWOS 07037  None  None  None     None      None     None   \n",
       "7  007044  99999   CWOS 07044  None  None  None     None      None     None   \n",
       "8  007047  99999   CWOS 07047  None  None  None     None      None     None   \n",
       "9  007052  99999   CWOS 07052  None  None  None     None      None     None   \n",
       "\n",
       "      BEGIN       END  \n",
       "0  20120127  20120127  \n",
       "1  20111025  20121129  \n",
       "2  20110309  20130730  \n",
       "3  20120127  20120127  \n",
       "4  20120713  20141120  \n",
       "5  20121024  20121106  \n",
       "6  20111202  20121125  \n",
       "7  20120127  20120127  \n",
       "8  20120613  20120717  \n",
       "9  20121129  20121130  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stations = spark.read \\\n",
    "    .option(\"header\", True) \\\n",
    "    .csv(storageLocation + \"/isd-history\")\n",
    "\n",
    "# Display first 10 records    \n",
    "stations.limit(10).toPandas()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1.3 Perform Analysis\n",
    "\n",
    "Now for completeness sake, let's reperform the analysis (minimum and maximum temperature per year and country) using `JOIN` and `GROUP BY` operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>CTRY</th>\n",
       "      <th>year</th>\n",
       "      <th>min_temp</th>\n",
       "      <th>max_temp</th>\n",
       "      <th>min_wind</th>\n",
       "      <th>max_wind</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>CA</td>\n",
       "      <td>2006</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>35.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>SC</td>\n",
       "      <td>2006</td>\n",
       "      <td>20.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>IC</td>\n",
       "      <td>2013</td>\n",
       "      <td>-11.0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>AM</td>\n",
       "      <td>2011</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>42.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>UK</td>\n",
       "      <td>2014</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>30.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SF</td>\n",
       "      <td>2012</td>\n",
       "      <td>2.2</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>GM</td>\n",
       "      <td>2005</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>NO</td>\n",
       "      <td>2007</td>\n",
       "      <td>-35.0</td>\n",
       "      <td>29.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>PO</td>\n",
       "      <td>2010</td>\n",
       "      <td>-1.6</td>\n",
       "      <td>38.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>FR</td>\n",
       "      <td>2010</td>\n",
       "      <td>-13.3</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>NL</td>\n",
       "      <td>2012</td>\n",
       "      <td>-18.4</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>28.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>US</td>\n",
       "      <td>2006</td>\n",
       "      <td>-43.0</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>AS</td>\n",
       "      <td>2012</td>\n",
       "      <td>0.1</td>\n",
       "      <td>43.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>DA</td>\n",
       "      <td>2003</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>PL</td>\n",
       "      <td>2008</td>\n",
       "      <td>-14.0</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>NL</td>\n",
       "      <td>2009</td>\n",
       "      <td>-17.9</td>\n",
       "      <td>34.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>27.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>GK</td>\n",
       "      <td>2013</td>\n",
       "      <td>-1.5</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>SC</td>\n",
       "      <td>2013</td>\n",
       "      <td>20.0</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>UK</td>\n",
       "      <td>2005</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>32.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>FR</td>\n",
       "      <td>2014</td>\n",
       "      <td>-9.0</td>\n",
       "      <td>36.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>IC</td>\n",
       "      <td>2008</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>22.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>31.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>FI</td>\n",
       "      <td>2010</td>\n",
       "      <td>-31.6</td>\n",
       "      <td>32.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>GM</td>\n",
       "      <td>2004</td>\n",
       "      <td>-10.2</td>\n",
       "      <td>30.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>GK</td>\n",
       "      <td>2005</td>\n",
       "      <td>-1.3</td>\n",
       "      <td>26.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>EZ</td>\n",
       "      <td>2003</td>\n",
       "      <td>-16.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>BE</td>\n",
       "      <td>2007</td>\n",
       "      <td>-8.3</td>\n",
       "      <td>33.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>LU</td>\n",
       "      <td>2012</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>SW</td>\n",
       "      <td>2014</td>\n",
       "      <td>-34.5</td>\n",
       "      <td>28.9</td>\n",
       "      <td>1.0</td>\n",
       "      <td>16.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>CA</td>\n",
       "      <td>2013</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>33.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>23.1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>PL</td>\n",
       "      <td>2012</td>\n",
       "      <td>-27.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>299</th>\n",
       "      <td>GK</td>\n",
       "      <td>2009</td>\n",
       "      <td>-3.0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>300</th>\n",
       "      <td>AS</td>\n",
       "      <td>2013</td>\n",
       "      <td>2.8</td>\n",
       "      <td>47.6</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>301</th>\n",
       "      <td>PL</td>\n",
       "      <td>2006</td>\n",
       "      <td>-29.0</td>\n",
       "      <td>33.1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>25.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>302</th>\n",
       "      <td>FI</td>\n",
       "      <td>2013</td>\n",
       "      <td>-32.7</td>\n",
       "      <td>29.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>20.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>303</th>\n",
       "      <td>US</td>\n",
       "      <td>2005</td>\n",
       "      <td>-49.0</td>\n",
       "      <td>43.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>33.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>304</th>\n",
       "      <td>AM</td>\n",
       "      <td>2006</td>\n",
       "      <td>-24.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>305</th>\n",
       "      <td>UK</td>\n",
       "      <td>2011</td>\n",
       "      <td>-5.2</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>306</th>\n",
       "      <td>AS</td>\n",
       "      <td>2005</td>\n",
       "      <td>2.6</td>\n",
       "      <td>43.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307</th>\n",
       "      <td>AU</td>\n",
       "      <td>2006</td>\n",
       "      <td>-19.4</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>SC</td>\n",
       "      <td>2012</td>\n",
       "      <td>21.0</td>\n",
       "      <td>36.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>26.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>309</th>\n",
       "      <td>IT</td>\n",
       "      <td>2007</td>\n",
       "      <td>-6.0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>18.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>310</th>\n",
       "      <td>UK</td>\n",
       "      <td>2008</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>28.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>24.2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>311</th>\n",
       "      <td>SF</td>\n",
       "      <td>2008</td>\n",
       "      <td>3.3</td>\n",
       "      <td>39.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>312</th>\n",
       "      <td>GM</td>\n",
       "      <td>2010</td>\n",
       "      <td>-13.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>313</th>\n",
       "      <td>FI</td>\n",
       "      <td>2003</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>29.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>14.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>314</th>\n",
       "      <td>FI</td>\n",
       "      <td>2006</td>\n",
       "      <td>-31.0</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>315</th>\n",
       "      <td>PO</td>\n",
       "      <td>2006</td>\n",
       "      <td>-1.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>316</th>\n",
       "      <td>GM</td>\n",
       "      <td>2012</td>\n",
       "      <td>-19.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>317</th>\n",
       "      <td>RS</td>\n",
       "      <td>2014</td>\n",
       "      <td>-28.9</td>\n",
       "      <td>30.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>318</th>\n",
       "      <td>FR</td>\n",
       "      <td>2006</td>\n",
       "      <td>-10.0</td>\n",
       "      <td>36.4</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>319</th>\n",
       "      <td>JA</td>\n",
       "      <td>2013</td>\n",
       "      <td>-0.3</td>\n",
       "      <td>34.5</td>\n",
       "      <td>0.0</td>\n",
       "      <td>38.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>US</td>\n",
       "      <td>2003</td>\n",
       "      <td>-44.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>35.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>321</th>\n",
       "      <td>IT</td>\n",
       "      <td>2008</td>\n",
       "      <td>-6.2</td>\n",
       "      <td>23.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>16.4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>322</th>\n",
       "      <td>FI</td>\n",
       "      <td>2011</td>\n",
       "      <td>-34.4</td>\n",
       "      <td>30.7</td>\n",
       "      <td>0.0</td>\n",
       "      <td>21.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>323</th>\n",
       "      <td>AU</td>\n",
       "      <td>2011</td>\n",
       "      <td>-15.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>324</th>\n",
       "      <td>JA</td>\n",
       "      <td>2014</td>\n",
       "      <td>-0.5</td>\n",
       "      <td>33.9</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>325</th>\n",
       "      <td>FR</td>\n",
       "      <td>2009</td>\n",
       "      <td>-11.1</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>19.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>326</th>\n",
       "      <td>MY</td>\n",
       "      <td>2007</td>\n",
       "      <td>20.0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327</th>\n",
       "      <td>LU</td>\n",
       "      <td>2007</td>\n",
       "      <td>-8.0</td>\n",
       "      <td>31.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>17.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>328</th>\n",
       "      <td>NO</td>\n",
       "      <td>2012</td>\n",
       "      <td>-33.0</td>\n",
       "      <td>24.8</td>\n",
       "      <td>0.0</td>\n",
       "      <td>39.6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>329 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    CTRY  year  min_temp  max_temp  min_wind  max_wind\n",
       "0     CA  2006     -43.0      35.9       0.0      31.4\n",
       "1     SC  2006      20.0      32.0       0.0      20.6\n",
       "2     IC  2013     -11.0      19.0       0.0      25.0\n",
       "3     AM  2011     -16.0      42.0       0.0      14.0\n",
       "4     UK  2014      -6.0      30.4       0.0      20.6\n",
       "5     SF  2012       2.2      36.0       0.0      10.3\n",
       "6     GM  2005     -14.0      31.0       0.0      14.4\n",
       "7     NO  2007     -35.0      29.0       0.0      26.0\n",
       "8     PO  2010      -1.6      38.0       0.0      21.6\n",
       "9     FR  2010     -13.3      36.1       0.0      17.5\n",
       "10    NL  2012     -18.4      35.0       0.0      28.8\n",
       "11    US  2006     -43.0      43.6       0.0      37.0\n",
       "12    AS  2012       0.1      43.6       0.0      13.9\n",
       "13    DA  2003     -16.0      30.0       0.0      23.0\n",
       "14    PL  2008     -14.0      30.0       0.0      25.7\n",
       "15    NL  2009     -17.9      34.8       0.0      27.8\n",
       "16    GK  2013      -1.5      26.0       0.0      20.1\n",
       "17    SC  2013      20.0      33.0       0.0      24.7\n",
       "18    UK  2005      -8.0      32.4       0.0      37.0\n",
       "19    FR  2014      -9.0      36.1       0.0      16.5\n",
       "20    IC  2008     -13.0      22.0       0.0      31.9\n",
       "21    FI  2010     -31.6      32.6       0.0      17.0\n",
       "22    GM  2004     -10.2      30.0       0.0      16.5\n",
       "23    GK  2005      -1.3      26.4       0.0      19.0\n",
       "24    EZ  2003     -16.0      37.0       0.0      16.5\n",
       "25    BE  2007      -8.3      33.0       0.0      21.1\n",
       "26    LU  2012     -15.0      35.0       0.0      13.9\n",
       "27    SW  2014     -34.5      28.9       1.0      16.0\n",
       "28    CA  2013     -44.0      33.8       0.0      23.1\n",
       "29    PL  2012     -27.0      34.0       0.0      13.4\n",
       "..   ...   ...       ...       ...       ...       ...\n",
       "299   GK  2009      -3.0      28.0       0.0      18.5\n",
       "300   AS  2013       2.8      47.6       0.0      13.4\n",
       "301   PL  2006     -29.0      33.1       0.0      25.7\n",
       "302   FI  2013     -32.7      29.9       0.0      20.0\n",
       "303   US  2005     -49.0      43.0       0.0      33.4\n",
       "304   AM  2006     -24.0      41.0       0.0      13.0\n",
       "305   UK  2011      -5.2      32.0       0.0      26.7\n",
       "306   AS  2005       2.6      43.4       0.0      12.9\n",
       "307   AU  2006     -19.4      34.0       0.0      12.3\n",
       "308   SC  2012      21.0      36.0       0.0      26.2\n",
       "309   IT  2007      -6.0      26.0       0.0      18.5\n",
       "310   UK  2008      -8.0      28.4       0.0      24.2\n",
       "311   SF  2008       3.3      39.8       0.0      11.3\n",
       "312   GM  2010     -13.0      34.0       0.0      17.0\n",
       "313   FI  2003     -33.0      29.4       0.0      14.4\n",
       "314   FI  2006     -31.0      27.0       0.0      12.0\n",
       "315   PO  2006      -1.0      37.0       0.0      16.5\n",
       "316   GM  2012     -19.0      34.0       0.0      13.9\n",
       "317   RS  2014     -28.9      30.5       0.0      11.0\n",
       "318   FR  2006     -10.0      36.4       0.0      15.9\n",
       "319   JA  2013      -0.3      34.5       0.0      38.0\n",
       "320   US  2003     -44.0      41.0       0.0      35.0\n",
       "321   IT  2008      -6.2      23.0       0.0      16.4\n",
       "322   FI  2011     -34.4      30.7       0.0      21.0\n",
       "323   AU  2011     -15.0      35.0       0.0      15.9\n",
       "324   JA  2014      -0.5      33.9       0.0      19.6\n",
       "325   FR  2009     -11.1      40.0       0.0      19.0\n",
       "326   MY  2007      20.0      35.0       0.0       9.8\n",
       "327   LU  2007      -8.0      31.0       0.0      17.0\n",
       "328   NO  2012     -33.0      24.8       0.0      39.6\n",
       "\n",
       "[329 rows x 6 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = weather.join(stations, (weather.usaf == stations.USAF) & (weather.wban == stations.WBAN))\n",
    "result = df.groupBy(df.CTRY, df.year).agg(\n",
    "        min(when(df.air_temperature_qual == lit(1), df.air_temperature)).alias('min_temp'),\n",
    "        max(when(df.air_temperature_qual == lit(1), df.air_temperature)).alias('max_temp'),\n",
    "        min(when(df.wind_speed_qual == lit(1), df.wind_speed)).alias('min_wind'),\n",
    "        max(when(df.wind_speed_qual == lit(1), df.wind_speed)).alias('max_wind')\n",
    "    )\n",
    "\n",
    "pdf = result.toPandas()    \n",
    "pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2 Investigate Execution Plans\n",
    "\n",
    "Now that we have redone the whole analysis, let's try to understand how Spark actually executes these steps. In order to understand the whole aggregation, we start simple and add one step after the other and look how execution plans change."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.1 Reading Data\n",
    "\n",
    "The first step is to read in data. In order to start simple, we only load a single year into a DataFrame called `raw_weather_2003`. We can inspect the execution plan that would create the records of that DataFrame with the `explain()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) FileScan text [value#321] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "raw_weather_2003 = spark.read.text(storageLocation + \"/2003\")\n",
    "raw_weather_2003.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we can see, the execution plan actually contains a single operation - reading data from disk. Note two things:\n",
    "* The phyiscal execution plan has been created specifically for the `explain()` command. It is not stored in the DataFrame, the DataFrame only contains the basis for a *parsed logical plan*\n",
    "* The plan is not executed, only printed to the console\n",
    "\n",
    "We can also inspect a more detailed execition plan, if we pass `True` to the `explain()` method as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Project [value#323, 2003 AS year#325]\n",
      "+- AnalysisBarrier\n",
      "      +- Relation[value#323] text\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "value: string, year: int\n",
      "Project [value#323, 2003 AS year#325]\n",
      "+- Relation[value#323] text\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [value#323, 2003 AS year#325]\n",
      "+- Relation[value#323] text\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [value#323, 2003 AS year#325]\n",
      "+- *(1) FileScan text [value#323] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "raw_weather_2003.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As you can see, the explanation now contains all four steps:\n",
    "* Parsed logical execution plan. This directly corresponds to the operations as specified.\n",
    "* Analyzed logical plan. This resolves all relations and columns and data types.\n",
    "* Optimized logical plan. This plan is already optimized (we'll see some optimizations later)\n",
    "* Physical execution plan. This maps all operations and transformations to RDD operations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.2 Adding Columns\n",
    "\n",
    "Let's see how the execution plan changes if we add a new column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Project [value#664, 2003 AS year#666]\n",
      "+- AnalysisBarrier\n",
      "      +- Relation[value#664] text\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "value: string, year: int\n",
      "Project [value#664, 2003 AS year#666]\n",
      "+- Relation[value#664] text\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [value#664, 2003 AS year#666]\n",
      "+- Relation[value#664] text\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [value#664, 2003 AS year#666]\n",
      "+- *(1) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "raw_weather_2003 = spark.read.text(storageLocation + \"/2003\").withColumn(\"year\", lit(2003))\n",
    "raw_weather_2003.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "We see that a `Project` operation was inserted to all execution plans which is responsible for adding the `year` column."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.3 SELECT Operation\n",
    "\n",
    "Now let's perform an additional `SELECT` operation after adding the year. We do not add all columns yet in order to keep the output small and more readable. We will add more columns later when we really require them."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Project [unresolvedalias('year, None), substring('value, 5, 6) AS usaf#949, substring('value, 11, 5) AS wban#950]\n",
      "+- AnalysisBarrier\n",
      "      +- Project [value#664, 2003 AS year#666]\n",
      "         +- Relation[value#664] text\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "year: int, usaf: string, wban: string\n",
      "Project [year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      "+- Project [value#664, 2003 AS year#666]\n",
      "   +- Relation[value#664] text\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      "+- Relation[value#664] text\n",
      "\n",
      "== Physical Plan ==\n",
      "*(1) Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      "+- *(1) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "weather_2003 = raw_weather_2003.select(\n",
    "    col(\"year\"),\n",
    "    substring(col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    substring(col(\"value\"),11,5).alias(\"wban\")\n",
    ")\n",
    "weather_2003.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "Here we see that the original parsed plan and analyzed plan actually contains two `Project` operations. Each of them corresponds to a single transformation (`withColumn` and `select`). But the optimizer merged these operations into a single one, thus simplifying execution."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.4 UNION Operation\n",
    "\n",
    "Just for completeness, let's see what a `UNION` operation does. We required it after loading all years into individual DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "Union\n",
      ":- *(1) Project [value#2, 2003 AS year#4]\n",
      ":  +- *(1) FileScan text [value#2] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(2) Project [value#7, 2004 AS year#9]\n",
      ":  +- *(2) FileScan text [value#7] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2004], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(3) Project [value#12, 2005 AS year#14]\n",
      ":  +- *(3) FileScan text [value#12] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2005], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(4) Project [value#17, 2006 AS year#19]\n",
      ":  +- *(4) FileScan text [value#17] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2006], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(5) Project [value#22, 2007 AS year#24]\n",
      ":  +- *(5) FileScan text [value#22] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2007], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(6) Project [value#27, 2008 AS year#29]\n",
      ":  +- *(6) FileScan text [value#27] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2008], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(7) Project [value#32, 2009 AS year#34]\n",
      ":  +- *(7) FileScan text [value#32] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2009], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(8) Project [value#37, 2010 AS year#39]\n",
      ":  +- *(8) FileScan text [value#37] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2010], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(9) Project [value#42, 2011 AS year#44]\n",
      ":  +- *(9) FileScan text [value#42] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2011], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(10) Project [value#47, 2012 AS year#49]\n",
      ":  +- *(10) FileScan text [value#47] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2012], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      ":- *(11) Project [value#52, 2013 AS year#54]\n",
      ":  +- *(11) FileScan text [value#52] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2013], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "+- *(12) Project [value#57, 2014 AS year#59]\n",
      "   +- *(12) FileScan text [value#57] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2014], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "# Read in all years, store them in an Python array\n",
    "raw_weather_per_year = [spark.read.text(storageLocation + \"/\" + str(i)).withColumn(\"year\", lit(i)) for i in range(2003,2015)]\n",
    "\n",
    "# Union all years together\n",
    "raw_weather = reduce(lambda l,r: l.union(r), raw_weather_per_year)                        \n",
    "\n",
    "# Print execution plan\n",
    "raw_weather.explain()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.5 JOIN Operation\n",
    "\n",
    "The next operation we had to perform was a `JOIN` between the measurements and the station metadata. We will use only a single year instead of the unioned data to keep output small and thereby increase readability of the execution plans."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Join Inner, ((usaf#949 = USAF#145) && (wban#950 = WBAN#146))\n",
      ":- Project [year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      ":  +- Project [value#664, 2003 AS year#666]\n",
      ":     +- Relation[value#664] text\n",
      "+- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "year: int, usaf: string, wban: string, USAF: string, WBAN: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string\n",
      "Join Inner, ((usaf#949 = USAF#145) && (wban#950 = WBAN#146))\n",
      ":- Project [year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      ":  +- Project [value#664, 2003 AS year#666]\n",
      ":     +- Relation[value#664] text\n",
      "+- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Join Inner, ((usaf#949 = USAF#145) && (wban#950 = WBAN#146))\n",
      ":- Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      ":  +- Filter (isnotnull(substring(value#664, 5, 6)) && isnotnull(substring(value#664, 11, 5)))\n",
      ":     +- Relation[value#664] text\n",
      "+- Filter (isnotnull(USAF#145) && isnotnull(WBAN#146))\n",
      "   +- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [usaf#949, wban#950], [USAF#145, WBAN#146], Inner, BuildRight\n",
      ":- *(2) Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#949, substring(value#664, 11, 5) AS wban#950]\n",
      ":  +- *(2) Filter (isnotnull(substring(value#664, 5, 6)) && isnotnull(substring(value#664, 11, 5)))\n",
      ":     +- *(2) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, string, true]))\n",
      "   +- *(1) Project [USAF#145, WBAN#146, STATION NAME#147, CTRY#148, STATE#149, ICAO#150, LAT#151, LON#152, ELEV(M)#153, BEGIN#154, END#155]\n",
      "      +- *(1) Filter (isnotnull(USAF#145) && isnotnull(WBAN#146))\n",
      "         +- *(1) FileScan csv [USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n"
     ]
    }
   ],
   "source": [
    "df = weather_2003.join(stations, (weather_2003.usaf == stations.USAF) & (weather_2003.wban == stations.WBAN))\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "Now a `JOIN` results in an interesting execution plan:\n",
    "* Spark filters columns, since an inner JOIN require non-null values\n",
    "* Filtering is actually pushed down before the projection. This reduces amount of data as soon as possible\n",
    "* JOIN operation is performed in two steps:\n",
    "  * Load data and broadcast it to all nodes (`BroadcastExchange`)\n",
    "  * Perform the join (`BroadcastHashJoin`)\n",
    "\n",
    "In addition to the *broadcast join* Spark also supports a different join implementation - more on that later."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Implicit Filtering\n",
    "\n",
    "Actually let's have a look at what happens with a left outer join. This should not filter away `NULL` values on the left side:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = weather_2003.join(stations, (weather_2003.usaf == stations.USAF) & (weather_2003.wban == stations.WBAN), how=\"left\")\n",
    "df.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.6 Aggregation\n",
    "\n",
    "Finally we want to perform an aggregation on the joined data. We need to restart from measurement extraction, since we did not extract all required columns so far. So we will perform the following steps\n",
    "* Reuse `raw_weather_2003` which already contains the `year` column\n",
    "* Extract all requirement measurements\n",
    "* Join with stations metadata\n",
    "* Perform grouped aggregation\n",
    "Again we will only analyze the temperature, just to keep execution plans a little bit smaller. This means that some columns are missing, but the basic operations are all the same."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Extract Measurements"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(1) Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, substring(value#664, 16, 8) AS date#1095, substring(value#664, 24, 4) AS time#1096, substring(value#664, 42, 5) AS report_type#1097, substring(value#664, 61, 3) AS wind_direction#1098, substring(value#664, 64, 1) AS wind_direction_qual#1099, substring(value#664, 65, 1) AS wind_observation#1100, (cast(cast(substring(value#664, 66, 4) as float) as double) / 10.0) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / 10.0) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      "+- *(1) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n"
     ]
    }
   ],
   "source": [
    "weather_2003 = raw_weather_2003.select(\n",
    "    col(\"year\"),\n",
    "    substring(col(\"value\"),5,6).alias(\"usaf\"),\n",
    "    substring(col(\"value\"),11,5).alias(\"wban\"),\n",
    "    substring(col(\"value\"),16,8).alias(\"date\"),\n",
    "    substring(col(\"value\"),24,4).alias(\"time\"),\n",
    "    substring(col(\"value\"),42,5).alias(\"report_type\"),\n",
    "    substring(col(\"value\"),61,3).alias(\"wind_direction\"),\n",
    "    substring(col(\"value\"),64,1).alias(\"wind_direction_qual\"),\n",
    "    substring(col(\"value\"),65,1).alias(\"wind_observation\"),\n",
    "    (substring(col(\"value\"),66,4).cast(\"float\") / lit(10.0)).alias(\"wind_speed\"),\n",
    "    substring(col(\"value\"),70,1).alias(\"wind_speed_qual\"),\n",
    "    (substring(col(\"value\"),88,5).cast(\"float\") / lit(10.0)).alias(\"air_temperature\"),\n",
    "    substring(col(\"value\"),93,1).alias(\"air_temperature_qual\")\n",
    ")\n",
    "weather_2003.explain(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Join with Stations Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Physical Plan ==\n",
      "*(2) BroadcastHashJoin [usaf#1093, wban#1094], [USAF#145, WBAN#146], Inner, BuildRight\n",
      ":- *(2) Project [2003 AS year#666, substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, substring(value#664, 16, 8) AS date#1095, substring(value#664, 24, 4) AS time#1096, substring(value#664, 42, 5) AS report_type#1097, substring(value#664, 61, 3) AS wind_direction#1098, substring(value#664, 64, 1) AS wind_direction_qual#1099, substring(value#664, 65, 1) AS wind_observation#1100, (cast(cast(substring(value#664, 66, 4) as float) as double) / 10.0) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / 10.0) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      ":  +- *(2) Filter (isnotnull(substring(value#664, 11, 5)) && isnotnull(substring(value#664, 5, 6)))\n",
      ":     +- *(2) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "+- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, string, true]))\n",
      "   +- *(1) Project [USAF#145, WBAN#146, STATION NAME#147, CTRY#148, STATE#149, ICAO#150, LAT#151, LON#152, ELEV(M)#153, BEGIN#154, END#155]\n",
      "      +- *(1) Filter (isnotnull(USAF#145) && isnotnull(WBAN#146))\n",
      "         +- *(1) FileScan csv [USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n"
     ]
    }
   ],
   "source": [
    "df = weather_2003.join(stations, (weather_2003.usaf == stations.USAF) & (weather_2003.wban == stations.WBAN))\n",
    "df.explain(False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Perform Grouped Aggregation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "'Aggregate [CTRY#148, year#666], [CTRY#148, year#666, min(CASE WHEN (air_temperature_qual#1104 = 1) THEN air_temperature#1103 END) AS min_temp#1215, max(CASE WHEN (air_temperature_qual#1104 = 1) THEN air_temperature#1103 END) AS max_temp#1217, min(CASE WHEN (wind_speed_qual#1102 = 1) THEN wind_speed#1101 END) AS min_wind#1219, max(CASE WHEN (wind_speed_qual#1102 = 1) THEN wind_speed#1101 END) AS max_wind#1221]\n",
      "+- AnalysisBarrier\n",
      "      +- Join Inner, ((usaf#1093 = USAF#145) && (wban#1094 = WBAN#146))\n",
      "         :- Project [year#666, substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, substring(value#664, 16, 8) AS date#1095, substring(value#664, 24, 4) AS time#1096, substring(value#664, 42, 5) AS report_type#1097, substring(value#664, 61, 3) AS wind_direction#1098, substring(value#664, 64, 1) AS wind_direction_qual#1099, substring(value#664, 65, 1) AS wind_observation#1100, (cast(cast(substring(value#664, 66, 4) as float) as double) / cast(10.0 as double)) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / cast(10.0 as double)) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      "         :  +- Project [value#664, 2003 AS year#666]\n",
      "         :     +- Relation[value#664] text\n",
      "         +- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "CTRY: string, year: int, min_temp: double, max_temp: double, min_wind: double, max_wind: double\n",
      "Aggregate [CTRY#148, year#666], [CTRY#148, year#666, min(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END) AS min_temp#1215, max(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END) AS max_temp#1217, min(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END) AS min_wind#1219, max(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END) AS max_wind#1221]\n",
      "+- Join Inner, ((usaf#1093 = USAF#145) && (wban#1094 = WBAN#146))\n",
      "   :- Project [year#666, substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, substring(value#664, 16, 8) AS date#1095, substring(value#664, 24, 4) AS time#1096, substring(value#664, 42, 5) AS report_type#1097, substring(value#664, 61, 3) AS wind_direction#1098, substring(value#664, 64, 1) AS wind_direction_qual#1099, substring(value#664, 65, 1) AS wind_observation#1100, (cast(cast(substring(value#664, 66, 4) as float) as double) / cast(10.0 as double)) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / cast(10.0 as double)) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      "   :  +- Project [value#664, 2003 AS year#666]\n",
      "   :     +- Relation[value#664] text\n",
      "   +- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Aggregate [CTRY#148, 2003], [CTRY#148, 2003 AS year#666, min(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END) AS min_temp#1215, max(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END) AS max_temp#1217, min(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END) AS min_wind#1219, max(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END) AS max_wind#1221]\n",
      "+- Project [wind_speed#1101, wind_speed_qual#1102, air_temperature#1103, air_temperature_qual#1104, CTRY#148]\n",
      "   +- Join Inner, ((usaf#1093 = USAF#145) && (wban#1094 = WBAN#146))\n",
      "      :- Project [substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, (cast(cast(substring(value#664, 66, 4) as float) as double) / 10.0) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / 10.0) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      "      :  +- Filter (isnotnull(substring(value#664, 11, 5)) && isnotnull(substring(value#664, 5, 6)))\n",
      "      :     +- Relation[value#664] text\n",
      "      +- Project [USAF#145, WBAN#146, CTRY#148]\n",
      "         +- Filter (isnotnull(USAF#145) && isnotnull(WBAN#146))\n",
      "            +- Relation[USAF#145,WBAN#146,STATION NAME#147,CTRY#148,STATE#149,ICAO#150,LAT#151,LON#152,ELEV(M)#153,BEGIN#154,END#155] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(3) HashAggregate(keys=[CTRY#148, 2003#1228], functions=[min(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END), max(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END), min(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END), max(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END)], output=[CTRY#148, year#666, min_temp#1215, max_temp#1217, min_wind#1219, max_wind#1221])\n",
      "+- Exchange hashpartitioning(CTRY#148, 2003#1228, 200)\n",
      "   +- *(2) HashAggregate(keys=[CTRY#148, 2003 AS 2003#1228], functions=[partial_min(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END), partial_max(CASE WHEN (cast(air_temperature_qual#1104 as int) = 1) THEN air_temperature#1103 END), partial_min(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END), partial_max(CASE WHEN (cast(wind_speed_qual#1102 as int) = 1) THEN wind_speed#1101 END)], output=[CTRY#148, 2003#1228, min#1233, max#1234, min#1235, max#1236])\n",
      "      +- *(2) Project [wind_speed#1101, wind_speed_qual#1102, air_temperature#1103, air_temperature_qual#1104, CTRY#148]\n",
      "         +- *(2) BroadcastHashJoin [usaf#1093, wban#1094], [USAF#145, WBAN#146], Inner, BuildRight\n",
      "            :- *(2) Project [substring(value#664, 5, 6) AS usaf#1093, substring(value#664, 11, 5) AS wban#1094, (cast(cast(substring(value#664, 66, 4) as float) as double) / 10.0) AS wind_speed#1101, substring(value#664, 70, 1) AS wind_speed_qual#1102, (cast(cast(substring(value#664, 88, 5) as float) as double) / 10.0) AS air_temperature#1103, substring(value#664, 93, 1) AS air_temperature_qual#1104]\n",
      "            :  +- *(2) Filter (isnotnull(substring(value#664, 11, 5)) && isnotnull(substring(value#664, 5, 6)))\n",
      "            :     +- *(2) FileScan text [value#664] Batched: false, Format: Text, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/2003], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<value:string>\n",
      "            +- BroadcastExchange HashedRelationBroadcastMode(List(input[0, string, true], input[1, string, true]))\n",
      "               +- *(1) Project [USAF#145, WBAN#146, CTRY#148]\n",
      "                  +- *(1) Filter (isnotnull(USAF#145) && isnotnull(WBAN#146))\n",
      "                     +- *(1) FileScan csv [USAF#145,WBAN#146,CTRY#148] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [IsNotNull(USAF), IsNotNull(WBAN)], ReadSchema: struct<USAF:string,WBAN:string,CTRY:string>\n"
     ]
    }
   ],
   "source": [
    "result = df.groupBy(df.CTRY, df.year).agg(\n",
    "        min(when(df.air_temperature_qual == lit(1), df.air_temperature)).alias('min_temp'),\n",
    "        max(when(df.air_temperature_qual == lit(1), df.air_temperature)).alias('max_temp')\n",
    "    )\n",
    "result.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "Again we can see that Spark performs some simple but clever optiomizations:\n",
    "* Projections only contains the columns required, not all available columns of df. The required columns are recursively *pushed up* the transformation chain from the last operation (grouped aggregation) to the first transformations\n",
    "* The aggregation is performed in three steps: \n",
    "  * Partial aggregation (`HashAggregate` with `partial_...` functions)\n",
    "  * Shuffle (`Exchange hashpartitioning`)\n",
    "  * Final aggregation of partial results (`HashAggregate`)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2.7 Sorting\n",
    "\n",
    "The last operation we like to analyze is sorting. To keep execution plans simple, we just sort the `stations` DataFrame by the stations IDs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "== Parsed Logical Plan ==\n",
      "Sort [usaf#143 ASC NULLS FIRST, wban#144 ASC NULLS FIRST], true\n",
      "+- AnalysisBarrier\n",
      "      +- Relation[USAF#143,WBAN#144,STATION NAME#145,CTRY#146,STATE#147,ICAO#148,LAT#149,LON#150,ELEV(M)#151,BEGIN#152,END#153] csv\n",
      "\n",
      "== Analyzed Logical Plan ==\n",
      "USAF: string, WBAN: string, STATION NAME: string, CTRY: string, STATE: string, ICAO: string, LAT: string, LON: string, ELEV(M): string, BEGIN: string, END: string\n",
      "Sort [usaf#143 ASC NULLS FIRST, wban#144 ASC NULLS FIRST], true\n",
      "+- Relation[USAF#143,WBAN#144,STATION NAME#145,CTRY#146,STATE#147,ICAO#148,LAT#149,LON#150,ELEV(M)#151,BEGIN#152,END#153] csv\n",
      "\n",
      "== Optimized Logical Plan ==\n",
      "Sort [usaf#143 ASC NULLS FIRST, wban#144 ASC NULLS FIRST], true\n",
      "+- Relation[USAF#143,WBAN#144,STATION NAME#145,CTRY#146,STATE#147,ICAO#148,LAT#149,LON#150,ELEV(M)#151,BEGIN#152,END#153] csv\n",
      "\n",
      "== Physical Plan ==\n",
      "*(2) Sort [usaf#143 ASC NULLS FIRST, wban#144 ASC NULLS FIRST], true, 0\n",
      "+- Exchange rangepartitioning(usaf#143 ASC NULLS FIRST, wban#144 ASC NULLS FIRST, 200)\n",
      "   +- *(1) FileScan csv [USAF#143,WBAN#144,STATION NAME#145,CTRY#146,STATE#147,ICAO#148,LAT#149,LON#150,ELEV(M)#151,BEGIN#152,END#153] Batched: false, Format: CSV, Location: InMemoryFileIndex[s3://dimajix-training/data/weather/isd-history], PartitionFilters: [], PushedFilters: [], ReadSchema: struct<USAF:string,WBAN:string,STATION NAME:string,CTRY:string,STATE:string,ICAO:string,LAT:strin...\n"
     ]
    }
   ],
   "source": [
    "result = stations.sort(stations[\"usaf\"], stations[\"wban\"])\n",
    "result.explain(True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Remarks\n",
    "\n",
    "In order to have a globally sorted result, it is not enough to sort within each Spark partition. This implies that some kind of shuffle operation has to be executed. In contrast to all our previous examples, this time Spark uses a `rangepartitioning` by which it simply splits up all data according to the range of the sorting key. After that is done, records will be sorted independently within each partition. Since the ranges were non-overlapping this is enough for a global ordering covering all partitions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
